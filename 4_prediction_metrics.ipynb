{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import General Relevant Libraries\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare list of file names for efficiently loading each prediction file later on. \n",
    "groundlist = ['cc256_ga_testlabels.npy', 'cc512_ga_testlabels.npy', 'cc256_ga_testlabels.npy', 'cc512_ga_testlabels.npy', 'cc256_ga_testlabels.npy', 'cc512_ga_testlabels.npy', 'jde256_ga_testlabels.npy', 'jde512_ga_testlabels.npy', 'jde256_ga_testlabels.npy', 'jde512_ga_testlabels.npy', 'jde256_ga_testlabels.npy', 'jde512_ga_testlabels.npy', 'jdi256_ga_testlabels.npy', 'jdi512_ga_testlabels.npy', 'jdi256_ga_testlabels.npy', 'jdi512_ga_testlabels.npy', 'jdi256_ga_testlabels.npy', 'jdi512_ga_testlabels.npy', 'sa256_ga_testlabels.npy', 'sa512_ga_testlabels.npy', 'sa256_ga_testlabels.npy', 'sa512_ga_testlabels.npy', 'sa256_ga_testlabels.npy', 'sa512_ga_testlabels.npy']\n",
    "featurelist = ['cc256_ga_test.npy', 'cc512_ga_test.npy', 'cc256_ga_test.npy', 'cc512_ga_test.npy', 'cc256_ga_test.npy', 'cc512_ga_test.npy', 'jde256_ga_test.npy', 'jde512_ga_test.npy', 'jde256_ga_test.npy', 'jde512_ga_test.npy', 'jde256_ga_test.npy', 'jde512_ga_test.npy', 'jdi256_ga_test.npy', 'jdi512_ga_test.npy', 'jdi256_ga_test.npy', 'jdi512_ga_test.npy', 'jdi256_ga_test.npy', 'jdi512_ga_test.npy', 'sa256_ga_test.npy', 'sa512_ga_test.npy', 'sa256_ga_test.npy', 'sa512_ga_test.npy', 'sa256_ga_test.npy', 'sa512_ga_test.npy']\n",
    "predlist = ['pred_stack_og_cc256g.npy', 'pred_stack_og_cc512g.npy', 'pred_stack_p2_cc256g.npy', 'pred_stack_p2_cc512g.npy', 'pred_stack_r_cc256g.npy', 'pred_stack_r_cc512g.npy', 'pred_stack_og_jde256g.npy', 'pred_stack_og_jde512g.npy', 'pred_stack_p2_jde256g.npy', 'pred_stack_p2_jde512g.npy', 'pred_stack_r_jde256g.npy', 'pred_stack_r_jde512g.npy', 'pred_stack_og_jdi256g.npy', 'pred_stack_og_jdi512g.npy', 'pred_stack_p2_jdi256g.npy', 'pred_stack_p2_jdi512g.npy', 'pred_stack_r_jdi256g.npy', 'pred_stack_r_jdi512g.npy', 'pred_stack_og_sa256g.npy', 'pred_stack_og_sa512g.npy', 'pred_stack_p2_sa256g.npy', 'pred_stack_p2_sa512g.npy', 'pred_stack_r_sa256g.npy', 'pred_stack_r_sa512g.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 24\n",
      "\n",
      "cc256_ga_testlabels.npy pred_stack_og_cc256g.npy\n",
      "cc512_ga_testlabels.npy pred_stack_og_cc512g.npy\n",
      "cc256_ga_testlabels.npy pred_stack_p2_cc256g.npy\n",
      "cc512_ga_testlabels.npy pred_stack_p2_cc512g.npy\n",
      "cc256_ga_testlabels.npy pred_stack_r_cc256g.npy\n",
      "cc512_ga_testlabels.npy pred_stack_r_cc512g.npy\n",
      "jde256_ga_testlabels.npy pred_stack_og_jde256g.npy\n",
      "jde512_ga_testlabels.npy pred_stack_og_jde512g.npy\n",
      "jde256_ga_testlabels.npy pred_stack_p2_jde256g.npy\n",
      "jde512_ga_testlabels.npy pred_stack_p2_jde512g.npy\n",
      "jde256_ga_testlabels.npy pred_stack_r_jde256g.npy\n",
      "jde512_ga_testlabels.npy pred_stack_r_jde512g.npy\n",
      "jdi256_ga_testlabels.npy pred_stack_og_jdi256g.npy\n",
      "jdi512_ga_testlabels.npy pred_stack_og_jdi512g.npy\n",
      "jdi256_ga_testlabels.npy pred_stack_p2_jdi256g.npy\n",
      "jdi512_ga_testlabels.npy pred_stack_p2_jdi512g.npy\n",
      "jdi256_ga_testlabels.npy pred_stack_r_jdi256g.npy\n",
      "jdi512_ga_testlabels.npy pred_stack_r_jdi512g.npy\n",
      "sa256_ga_testlabels.npy pred_stack_og_sa256g.npy\n",
      "sa512_ga_testlabels.npy pred_stack_og_sa512g.npy\n",
      "sa256_ga_testlabels.npy pred_stack_p2_sa256g.npy\n",
      "sa512_ga_testlabels.npy pred_stack_p2_sa512g.npy\n",
      "sa256_ga_testlabels.npy pred_stack_r_sa256g.npy\n",
      "sa512_ga_testlabels.npy pred_stack_r_sa512g.npy\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check: check matching ground files and predicted files, in the preferred order. \n",
    "print(len(groundlist),len(featurelist),len(predlist))\n",
    "print()\n",
    "for a, b in zip(groundlist, predlist):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information about predictions files: \n",
    "\"\"\"\n",
    "Prediction files consist of arrays with a identical shape as the testlabel arrays. \n",
    "Wlements are numbers between 0 and 1 that are output from the sigmoid activation function. \n",
    "We consider values (representing pixels) equal or greater than 0.5 part of the label. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for converting the prediction values to binary values (0=not part of label, 1= part of label)\n",
    "def threshold_to_binary(array, threshold=0.5):\n",
    "    return (array >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7138140270119578, 0.9447440636081135, 0.9584012902502027, 0.8781650719144819, 0.8555313535018441],\n",
      "[0.44707649625173396, 0.8557559260887408, 0.9286614855239944, 0.8189874185795579, 0.6330052537075215],\n",
      "[0.5837402804832643, 0.9467238809777536, 0.9606070346383595, 0.8700063109572554, 0.8587045563941186],\n",
      "[0.21647123126671522, 0.87530490092225, 0.9383666919566385, 0.8207068003148493, 0.4124513427822511],\n",
      "[0.7552206914387439, 0.9483009742323425, 0.9600182657026745, 0.8810945913902439, 0.8638881729824178],\n",
      "[0.6319368548876746, 0.9241523959448436, 0.9526608646930542, 0.8602828437082752, 0.774800570215541],\n",
      "[0.7705856211389303, 0.9453677340813155, 0.7928980048399574, 0.8763211652942063, 0.7909491531994908],\n",
      "[0.598721405162811, 0.9178414970723895, 0.7844983604946763, 0.8317128894625888, 0.7203484542932413],\n",
      "[0.7414670613788937, 0.9440961456395656, 0.7264422854921484, 0.8743067835410747, 0.7693589111203833],\n",
      "[0.41608606396815695, 0.9060776718441002, 0.7012922120482579, 0.8244124259747448, 0.44190579509531874],\n",
      "[0.7331764773464371, 0.9477258866193609, 0.7760496655873403, 0.8767128163957768, 0.7923348690111384],\n",
      "[0.5606373737770216, 0.9151988707178688, 0.7700795580008158, 0.8413938706169598, 0.7213683305070858],\n",
      "[0.35748063590468726, 0.8595817561299678, 0.9613249014329867, 0.8212787346606067, 0.8843248830183653],\n",
      "[0.03325305002346831, 0.7981614366568823, 0.9604645318749756, 0.7900141438397352, 0.8556809870457678],\n",
      "[0.18146492263635816, 0.7793819748044374, 0.9519772554840222, 0.7676550444743587, 0.7860397351682153],\n",
      "[0.0, 0.6381717002987527, 0.952941786253699, 0.658917870425877, 0.4733148803427165],\n",
      "[0.38156995801060867, 0.8640509410194823, 0.9623681566948257, 0.7930670431538516, 0.876843557652948],\n",
      "[0.042054774170524264, 0.7921377813692135, 0.95762104816914, 0.7751307025675174, 0.800368304912502],\n",
      "[0.7535819743838112, 0.9339265181099087, 0.951634009352921, 0.8701505082462246, 0.8579101835298061],\n",
      "[0.57939488094077, 0.9096538648312141, 0.9461479292614174, 0.8452606771844732, 0.7653702504949318],\n",
      "[0.700553804470322, 0.9358538381562987, 0.953342226041786, 0.872644747273717, 0.8382285664396717],\n",
      "[0.4174280169540833, 0.8944962637523969, 0.9398670810026648, 0.8309053511088224, 0.6994184611803049],\n",
      "[0.7041000829612682, 0.9352262688178231, 0.9500441057092734, 0.8719255793455264, 0.8318487042283076],\n",
      "[0.5137853638689065, 0.8888413638196606, 0.9403826525397352, 0.8258378677335195, 0.7402601853121076],\n"
     ]
    }
   ],
   "source": [
    "### Computing the IoU score of each prediction file\n",
    "\n",
    "array = []\n",
    "for a, b in zip(groundlist, predlist):\n",
    "    # Specify Input Path of ground truth\n",
    "    os.chdir('C:/Users/quint/OneDrive/qthesis/02_datasets/matrices/train_test_matrices/greedy/')\n",
    "    ground = np.load(a)\n",
    "    # Specify Input Path of prediction\n",
    "    os.chdir('C:/Users/quint/OneDrive/qthesis/02_datasets/matrices/prediction_matrices/')\n",
    "    pred = np.load(b)\n",
    "\n",
    "    pred = threshold_to_binary(pred) # Convert prediction values to binary values\n",
    "    \n",
    "    # Compute the number of TPs, TNs, FPs, and FNs per label. \n",
    "    TP = np.sum(np.logical_and(pred == 1, ground == 1), axis=(0, 1, 2))\n",
    "    TN = np.sum(np.logical_and(pred == 0, ground == 0), axis=(0, 1, 2))\n",
    "    FP = np.sum(np.logical_and(pred == 1, ground == 0), axis=(0, 1, 2))\n",
    "    FN = np.sum(np.logical_and(pred == 0, ground == 1), axis=(0, 1, 2))\n",
    "    # Each variable has a shape of (5,)\n",
    "    #print(TP.shape, TN.shape, FP.shape, FN.shape)\n",
    "\n",
    "    # Compute the IoU score for each label\n",
    "    IoU_labels = []\n",
    "    for i in range(5):\n",
    "        IoU = TP[i] / (TP[i] + FP[i] + FN[i])\n",
    "        IoU_labels.append(IoU)\n",
    "    print(f'{IoU_labels},')\n",
    "    array.append(IoU_labels)\n",
    "\n",
    "iou_array = np.array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71.38 94.47 95.84 87.82 85.55]\n",
      " [44.71 85.58 92.87 81.9  63.3 ]\n",
      " [58.37 94.67 96.06 87.   85.87]\n",
      " [21.65 87.53 93.84 82.07 41.25]\n",
      " [75.52 94.83 96.   88.11 86.39]\n",
      " [63.19 92.42 95.27 86.03 77.48]\n",
      " [77.06 94.54 79.29 87.63 79.09]\n",
      " [59.87 91.78 78.45 83.17 72.03]\n",
      " [74.15 94.41 72.64 87.43 76.94]\n",
      " [41.61 90.61 70.13 82.44 44.19]\n",
      " [73.32 94.77 77.6  87.67 79.23]\n",
      " [56.06 91.52 77.01 84.14 72.14]\n",
      " [35.75 85.96 96.13 82.13 88.43]\n",
      " [ 3.33 79.82 96.05 79.   85.57]\n",
      " [18.15 77.94 95.2  76.77 78.6 ]\n",
      " [ 0.   63.82 95.29 65.89 47.33]\n",
      " [38.16 86.41 96.24 79.31 87.68]\n",
      " [ 4.21 79.21 95.76 77.51 80.04]\n",
      " [75.36 93.39 95.16 87.02 85.79]\n",
      " [57.94 90.97 94.61 84.53 76.54]\n",
      " [70.06 93.59 95.33 87.26 83.82]\n",
      " [41.74 89.45 93.99 83.09 69.94]\n",
      " [70.41 93.52 95.   87.19 83.18]\n",
      " [51.38 88.88 94.04 82.58 74.03]]\n"
     ]
    }
   ],
   "source": [
    "# Convert IoU decimal-numbers to percentages, rounded to 2 decimals. \n",
    "iou_array = np.around((iou_array*100),2)\n",
    "print(iou_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8330173324969875, 0.970310849591037, 0.9777998851708954, 0.9345037237420585, 0.9263995448537338],\n",
      "[0.6574472571063706, 0.9408391979708092, 0.9706257291465907, 0.9085344219488927, 0.7855604368285571],\n",
      "[0.7918258083103924, 0.9741208449461902, 0.9808339436302953, 0.9270784120162753, 0.9321381769878226],\n",
      "[0.4346005466198815, 0.9425240893449327, 0.9695809624230837, 0.9024370859803803, 0.6517540720511599],\n",
      "[0.8644457930445041, 0.9747986416891816, 0.9808888423410025, 0.9348406665526791, 0.9221960537377517],\n",
      "[0.7817902033932245, 0.9628958399449331, 0.9757429136558452, 0.9266737537441669, 0.8730909354483958],\n",
      "[0.8792030867658682, 0.9734514030341662, 0.8887709490005112, 0.9394098996400587, 0.8917674579067383],\n",
      "[0.7844583216403224, 0.9526488629451737, 0.8744080896046983, 0.9175797828756865, 0.8346821862594728],\n",
      "[0.8428533558920399, 0.9701746782501584, 0.8424187789762673, 0.9337379764346001, 0.8756465142447497],\n",
      "[0.6398074388202001, 0.9471782127094126, 0.8365020581670954, 0.9096483592975633, 0.682311038015525],\n",
      "[0.8716346546850623, 0.9748513801234086, 0.8716841972187892, 0.938667129020069, 0.8914214912879349],\n",
      "[0.7780673460219386, 0.9534583418607524, 0.8625067218793089, 0.9072044824254951, 0.8258068038708417],\n",
      "[0.580762977777023, 0.9360988991177162, 0.9797348100838033, 0.9017048378295689, 0.9359426802838448],\n",
      "[0.09306031448507307, 0.9052196908739233, 0.978122556283278, 0.8824523774157353, 0.917592640414613],\n",
      "[0.3730072227173624, 0.8840423567324328, 0.9777765139706085, 0.8785668320072452, 0.8705066832954604],\n",
      "[0, 0.8024101718781208, 0.9774309167427676, 0.835603350642832, 0.677683485588549],\n",
      "[0.6088747185389002, 0.92799205660092, 0.9821347823807604, 0.9038269113614573, 0.9325515399352736],\n",
      "[0.11545328541062638, 0.887929326997621, 0.9782516168676272, 0.8830272594090892, 0.8943128552137853],\n",
      "[0.8624296937989281, 0.9640064108239427, 0.9744522310986653, 0.9283058212959, 0.9260080905159468],\n",
      "[0.7503474386444393, 0.9528456496323267, 0.9717825341254579, 0.9155874484562933, 0.8733766935616379],\n",
      "[0.8374064981029069, 0.9682396326926981, 0.9772952065387065, 0.9342674934869438, 0.9178006839758206],\n",
      "[0.6440590846114692, 0.9474869103808511, 0.969063680821654, 0.9053626983994277, 0.8363050802726478],\n",
      "[0.8397070087040018, 0.9668187291858114, 0.9731979657757666, 0.9354103886402695, 0.9155391509344317],\n",
      "[0.6939483450534677, 0.9423251968044608, 0.9719311016397683, 0.9093238117609685, 0.8556446895652254],\n"
     ]
    }
   ],
   "source": [
    "### Computing the F-beta score of each prediction file\n",
    "\n",
    "beta = 0.707\n",
    "array = []\n",
    "for a, b in zip(groundlist, predlist):\n",
    "    # Specify Input Path of ground truth\n",
    "    os.chdir('C:/Users/quint/OneDrive/qthesis/02_datasets/matrices/train_test_matrices/greedy/')\n",
    "    ground = np.load(a)\n",
    "    # Specify Input Path of prediction\n",
    "    os.chdir('C:/Users/quint/OneDrive/qthesis/02_datasets/matrices/prediction_matrices/')\n",
    "    pred = np.load(b)\n",
    "\n",
    "    pred = threshold_to_binary(pred) # Convert prediction values to binary values\n",
    "\n",
    "    # Compute the number of TPs, TNs, FPs, and FNs per label. \n",
    "    TP = np.sum(np.logical_and(pred == 1, ground == 1), axis=(0, 1, 2))\n",
    "    TN = np.sum(np.logical_and(pred == 0, ground == 0), axis=(0, 1, 2))\n",
    "    FP = np.sum(np.logical_and(pred == 1, ground == 0), axis=(0, 1, 2))\n",
    "    FN = np.sum(np.logical_and(pred == 0, ground == 1), axis=(0, 1, 2))\n",
    "    # Each variable has a shape of (5,)\n",
    "    #print(TP.shape, TN.shape, FP.shape, FN.shape)\n",
    "\n",
    "    # Compute the F-beta score for each label\n",
    "    FB_labels = []\n",
    "    for i in range(5):\n",
    "        precision = TP[i] / (TP[i] + FP[i]) if TP[i] + FP[i] > 0 else 0\n",
    "        recall = TP[i] / (TP[i] + FN[i]) if TP[i] + FN[i] > 0 else 0\n",
    "        FB = (1 + beta**2) * precision * recall / (beta**2 * precision + recall) if (beta**2 * precision + recall) > 0 else 0\n",
    "        FB_labels.append(FB)\n",
    "    print(f'{FB_labels},')\n",
    "    array.append(FB_labels)\n",
    "\n",
    "fb_array = np.array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83.3  97.03 97.78 93.45 92.64]\n",
      " [65.74 94.08 97.06 90.85 78.56]\n",
      " [79.18 97.41 98.08 92.71 93.21]\n",
      " [43.46 94.25 96.96 90.24 65.18]\n",
      " [86.44 97.48 98.09 93.48 92.22]\n",
      " [78.18 96.29 97.57 92.67 87.31]\n",
      " [87.92 97.35 88.88 93.94 89.18]\n",
      " [78.45 95.26 87.44 91.76 83.47]\n",
      " [84.29 97.02 84.24 93.37 87.56]\n",
      " [63.98 94.72 83.65 90.96 68.23]\n",
      " [87.16 97.49 87.17 93.87 89.14]\n",
      " [77.81 95.35 86.25 90.72 82.58]\n",
      " [58.08 93.61 97.97 90.17 93.59]\n",
      " [ 9.31 90.52 97.81 88.25 91.76]\n",
      " [37.3  88.4  97.78 87.86 87.05]\n",
      " [ 0.   80.24 97.74 83.56 67.77]\n",
      " [60.89 92.8  98.21 90.38 93.26]\n",
      " [11.55 88.79 97.83 88.3  89.43]\n",
      " [86.24 96.4  97.45 92.83 92.6 ]\n",
      " [75.03 95.28 97.18 91.56 87.34]\n",
      " [83.74 96.82 97.73 93.43 91.78]\n",
      " [64.41 94.75 96.91 90.54 83.63]\n",
      " [83.97 96.68 97.32 93.54 91.55]\n",
      " [69.39 94.23 97.19 90.93 85.56]]\n"
     ]
    }
   ],
   "source": [
    "# Convert Fbeta decimal-numbers to percentages, rounded to 2 decimals. \n",
    "fb_array = np.around((fb_array*100),2)\n",
    "print(fb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77.06 94.83 96.24 88.11 88.43]\n",
      "[87.92 97.49 98.21 93.94 93.59]\n"
     ]
    }
   ],
   "source": [
    "# Find the highest scores for each evaluation metric.\n",
    "\n",
    "iou_max = np.amax(iou_array, axis=0)\n",
    "print(iou_max)\n",
    "\n",
    "fb_max = np.amax(fb_array, axis=0)\n",
    "print(fb_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasciencecourses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
